{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}\n",
    "\n",
    "def mnist_dataset():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "    x_train = train_dataset.data.float() / 255.0\n",
    "    y_train = train_dataset.targets\n",
    "\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "    x_test = test_dataset.data.float() / 255.0\n",
    "    y_test = test_dataset.targets\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip([1, 2, 3, 4], ['a', 'b', 'c', 'd'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myModel, self).__init__()\n",
    "        self.W1 = nn.Parameter(torch.randn(784, 128))\n",
    "        self.b1 = nn.Parameter(torch.zeros(128))\n",
    "        self.W2 = nn.Parameter(torch.randn(128, 10))\n",
    "        self.b2 = nn.Parameter(torch.zeros(10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        h1 = torch.matmul(x, self.W1) + self.b1\n",
    "        h1 = torch.relu(h1)\n",
    "        logits = torch.matmul(h1, self.W2) + self.b2\n",
    "        return logits\n",
    "    \n",
    "model = myModel()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(logits, labels):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return criterion(logits, labels)\n",
    "\n",
    "def compute_accuracy(logits, labels):\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "    correct = (predictions == labels).float().sum()\n",
    "    return correct / len(labels)\n",
    "\n",
    "def train_one_step(model, optimizer, x, y):\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(x)\n",
    "    loss = compute_loss(logits, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    accuracy = compute_accuracy(logits, y)\n",
    "    return loss, accuracy\n",
    "\n",
    "def test(model, x, y):\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        loss = compute_loss(logits, y)\n",
    "        accuracy = compute_accuracy(logits, y)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实际训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: loss 5.3024187088012695; accuracy 0.8157166838645935\n",
      "epoch 1: loss 5.288545608520508; accuracy 0.8160499930381775\n",
      "epoch 2: loss 5.274740695953369; accuracy 0.8163833618164062\n",
      "epoch 3: loss 5.261007308959961; accuracy 0.8167666792869568\n",
      "epoch 4: loss 5.247347354888916; accuracy 0.8170666694641113\n",
      "epoch 5: loss 5.233755588531494; accuracy 0.8173999786376953\n",
      "epoch 6: loss 5.220232963562012; accuracy 0.8176666498184204\n",
      "epoch 7: loss 5.206782341003418; accuracy 0.818149983882904\n",
      "epoch 8: loss 5.193399429321289; accuracy 0.8185166716575623\n",
      "epoch 9: loss 5.180081844329834; accuracy 0.8189666867256165\n",
      "epoch 10: loss 5.1668291091918945; accuracy 0.8191666603088379\n",
      "epoch 11: loss 5.153646945953369; accuracy 0.819516658782959\n",
      "epoch 12: loss 5.140530109405518; accuracy 0.8199166655540466\n",
      "epoch 13: loss 5.127477169036865; accuracy 0.8203166723251343\n",
      "epoch 14: loss 5.1144843101501465; accuracy 0.8205500245094299\n",
      "epoch 15: loss 5.101556777954102; accuracy 0.820900022983551\n",
      "epoch 16: loss 5.0886921882629395; accuracy 0.8212000131607056\n",
      "epoch 17: loss 5.075887203216553; accuracy 0.821566641330719\n",
      "epoch 18: loss 5.0631489753723145; accuracy 0.8219166398048401\n",
      "epoch 19: loss 5.050480842590332; accuracy 0.8221833109855652\n",
      "epoch 20: loss 5.037874698638916; accuracy 0.8224666714668274\n",
      "epoch 21: loss 5.025338172912598; accuracy 0.822783350944519\n",
      "epoch 22: loss 5.01286506652832; accuracy 0.823116660118103\n",
      "epoch 23: loss 5.000453948974609; accuracy 0.8234000205993652\n",
      "epoch 24: loss 4.988108158111572; accuracy 0.8236333131790161\n",
      "epoch 25: loss 4.975825309753418; accuracy 0.8239666819572449\n",
      "epoch 26: loss 4.963603496551514; accuracy 0.8244500160217285\n",
      "epoch 27: loss 4.95144510269165; accuracy 0.8248833417892456\n",
      "epoch 28: loss 4.939351558685303; accuracy 0.8252166509628296\n",
      "epoch 29: loss 4.927318096160889; accuracy 0.8255000114440918\n",
      "epoch 30: loss 4.91534948348999; accuracy 0.8258666396141052\n",
      "epoch 31: loss 4.903441429138184; accuracy 0.82628333568573\n",
      "epoch 32: loss 4.891594409942627; accuracy 0.826449990272522\n",
      "epoch 33: loss 4.87980842590332; accuracy 0.8267499804496765\n",
      "epoch 34: loss 4.8680853843688965; accuracy 0.8272666931152344\n",
      "epoch 35: loss 4.856419086456299; accuracy 0.8275833129882812\n",
      "epoch 36: loss 4.8448076248168945; accuracy 0.8278833627700806\n",
      "epoch 37: loss 4.833255767822266; accuracy 0.8282666802406311\n",
      "epoch 38: loss 4.821764945983887; accuracy 0.8286166787147522\n",
      "epoch 39: loss 4.810332775115967; accuracy 0.8288499712944031\n",
      "epoch 40: loss 4.798952102661133; accuracy 0.8291500210762024\n",
      "epoch 41: loss 4.787629127502441; accuracy 0.82955002784729\n",
      "epoch 42: loss 4.776364803314209; accuracy 0.830049991607666\n",
      "epoch 43: loss 4.765157222747803; accuracy 0.8302666544914246\n",
      "epoch 44: loss 4.754003524780273; accuracy 0.8305500149726868\n",
      "epoch 45: loss 4.7429022789001465; accuracy 0.8308500051498413\n",
      "epoch 46: loss 4.731857776641846; accuracy 0.8310166597366333\n",
      "epoch 47: loss 4.720867156982422; accuracy 0.8312333226203918\n",
      "epoch 48: loss 4.709931373596191; accuracy 0.8314999938011169\n",
      "epoch 49: loss 4.699052810668945; accuracy 0.831933319568634\n",
      "test loss 4.835417747497559; accuracy 0.8284000158309937\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = mnist_dataset()\n",
    "for epoch in range(50):\n",
    "    loss, accuracy = train_one_step(model, optimizer,\n",
    "                                    train_data[0],\n",
    "                                    train_data[1])\n",
    "    print(f'epoch {epoch}: loss {loss.item()}; accuracy {accuracy.item()}')\n",
    "\n",
    "loss, accuracy = test(model,\n",
    "                      test_data[0],\n",
    "                      test_data[1])\n",
    "\n",
    "print(f'test loss {loss.item()}; accuracy {accuracy.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
